{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data points:  2002\n",
      "Starting with [0.    0.005 0.01  0.015 0.02 ]\n",
      "Ending with [ 9.985  9.99   9.995 10.    10.005]\n",
      "Data elements 2002\n"
     ]
    }
   ],
   "source": [
    "# Import the dependencies\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz, cholesky, sqrtm, inv\n",
    "# import scipy.linalg as la\n",
    "from scipy import signal\n",
    "#from scipy.integrate import odeint\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Setting up the time data:\n",
    "dt = 0.005; # integration time step, average neuron resets 200 times per second\n",
    "T = 10+dt; # maximum time considered\n",
    "t = np.arange(0,T,dt) # timline\n",
    "N= t.size #Amount of data points\n",
    "print ('Amount of data points: ', N)\n",
    "print ('Starting with', t[0:5])\n",
    "print ('Ending with', t[N-5:N])\n",
    "pri nt ('Data elements', np.size(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support functions for generalised coordinates of motion\n",
    "\n",
    "def generalize_extend(y,p):\n",
    "    \"\"\"\n",
    "    Construct generalised value with embedding order p \n",
    "    By [y,0,0...]\n",
    "    \n",
    "    INPUTS:\n",
    "        y       - Input sensory signal\n",
    "        p       - embedding order (>0)\n",
    "        \n",
    "    OUTPUT:\n",
    "        y_tilde - Generalised sensory signal\n",
    "    \"\"\" \n",
    "    if p<0:\n",
    "        # unknown embedding order, error\n",
    "        raise ValueError('Embedding order < 0')    \n",
    "    \n",
    "    if np.shape(y)==(p+1, 1):\n",
    "        # Generalised value, use it\n",
    "        y_tilde=y;\n",
    "        return y_tilde\n",
    "    \n",
    "    # Generalize sensory observation by adding zero's\n",
    "    y_tilde = np.zeros((p+1,1))\n",
    "    y_tilde[0] = y\n",
    "\n",
    "    return y_tilde\n",
    "\n",
    "def sensor_generalize_exact(y,p,x,v,u):\n",
    "    \"\"\"\n",
    "    Construct generalised sensory observations with embedding order p \n",
    "    Generalize sensory observation by calculating the exact value \n",
    "    \n",
    "    For this example it has been calculated upto 3 derivatives\n",
    "\n",
    "    INPUTS:\n",
    "        y       - Input sensory signal\n",
    "        p       - embedding order (>0)\n",
    "        x       - Hidden state, needed to calculate the exact higher derivatives\n",
    "        \n",
    "    OUTPUT:\n",
    "        y_tilde - Generalised sensory signal\n",
    "    \"\"\" \n",
    "    if p<0:\n",
    "        # unknown embedding order, error\n",
    "        raise ValueError('Embedding order < 0')       \n",
    "\n",
    "    y_tilde = np.zeros((p+1,1))\n",
    "    y_tilde[0] = y\n",
    "    if p>=1:\n",
    "        y_tilde[1] = dg_gp(x,v)*f_gp(x,v,u) \n",
    "    if p>=2:\n",
    "        y_tilde[2] = ddg_gp(x,v)*f_gp(x,v,u)**2 + dg_gp(x,v)*df_gp(x,v,u)*f_gp(x,v,u)\n",
    "    if p>=3:\n",
    "        y_tilde[3] = dddg_gp(x,v)*f_gp(x,v,u)**3 + 2*ddg_gp(x,v)*f_gp(x,v,u)**2*df_gp(x,v,u) + df_gp(x,v,u)*(ddg_gp(x,v)*f_gp(x,v,u)**2 + dg_gp(x,v)*df_gp(x,v,u)*f_gp(x,v,u))\n",
    "    \n",
    "    return y_tilde\n",
    "\n",
    "def sensor_generalize_backward(y,i,p):\n",
    "    \"\"\"\n",
    "    Construct generalised sensory observations with embedding order p \n",
    "    Generalize sensory observation by approximating the derivaties from past observations\n",
    "    \n",
    "    For this example it has been calculated upto 4 derivatives\n",
    "    \n",
    "    INPUTS:\n",
    "        y       - Input sensory signal (array including all history thus far)\n",
    "        i       - Current timestamp, so y[i] is the current non-generalised sensory signal\n",
    "        p       - embedding order (>=0)\n",
    "        \n",
    "    OUTPUT:\n",
    "        y_tilde - Generalised sensory signal\n",
    "    \"\"\" \n",
    "    if p<0:\n",
    "        # unknown embedding order, error\n",
    "        raise ValueError('Embedding order < 0')    \n",
    "    \n",
    "    y_tilde = np.zeros((p+1,1))\n",
    "    y_tilde[0] = y[i]\n",
    "    if p>=1:\n",
    "        y_tilde[1] = (y[i]-y[i-1])/dt\n",
    "        #print('Generalise backward input : ', y[i],' + ',y[i-1])\n",
    "    if p>=2 and i>=2:\n",
    "        y_tilde[2] = (y[i]-2*y[i-1]+y[i-2])/dt**2\n",
    "        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2])\n",
    "    if p>=3 and i>=3:\n",
    "        y_tilde[3] = (y[i]-3*y[i-1]+3*y[i-2]-y[i-3])/dt**3\n",
    "        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3])\n",
    "    if p>=4 and i>=4:\n",
    "        y_tilde[4] = (y[i]-4*y[i-1]+6*y[i-2]-4*y[i-3]+y[i-4])/dt**4\n",
    "        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3],' + ',y[i-4])\n",
    "          \n",
    "    return y_tilde\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature at 25 centimetres is:  17.0  degrees celsius\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_gp=0\n",
    "b_gp=1\n",
    "def f_gp(x, v, u):\n",
    "    \"\"\"\n",
    "    Generative process, equation of motion: f_gp(x,u)    \n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Hidden state, depth position in centimetres\n",
    "        v       - Causal state\n",
    "        u       - Control signal\n",
    "        \n",
    "    OUTPUT:\n",
    "        f_gp(x,v,u) - motion (speed) of the hidden state (depth) \n",
    "        \n",
    "    \"\"\"\n",
    "    return a_gp*x + b_gp*u\n",
    "\n",
    "def df_gp(x, v, u):\n",
    "    \"\"\"\n",
    "    Partial derivative of generative process towards x, equation of motion: f'_gp(x,v,u) at point x    \n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Hidden state, depth position in centimetres\n",
    "        v       - Causal state\n",
    "        u       - Control signal\n",
    "        \n",
    "    OUTPUT:\n",
    "        df_gp(x, u) - first derivative of the equation of motion towards x\n",
    "        \n",
    "    \"\"\"\n",
    "    return a_gp\n",
    "\n",
    "def g_gp(x,v):\n",
    "    \"\"\"\n",
    "    Generative process, equation of sensory mapping: g_gp(x,v)   \n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Hidden state, depth position in centimetres\n",
    "        v       - Hidden causal state, in this example not used\n",
    "        \n",
    "    OUTPUT:\n",
    "        g_gp(x,v) - Temperature in degrees celsius\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    t0=25\n",
    "    return t0 -16 / (1 + np.exp(5-x/5))\n",
    "\n",
    "def dg_gp(x,v):\n",
    "    \"\"\"\n",
    "    Partial derivative of generative process towards x, equation of sensory mapping: g'_gp(x,v)   \n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Position in centimetres    \n",
    "        \n",
    "    OUTPUT:\n",
    "        g'_gp(x,v) - first partial derivative of generative process towards x\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return -16/5 * np.exp(5-x/5) / (1+np.exp(5-x/5))**2\n",
    "\n",
    "def ddg_gp(x,v):\n",
    "    \"\"\"\n",
    "    Double partial derivative of generative process towards x, equation of sensory mapping: g''_gp(x) \n",
    "    Needed to calculate the sensory signal in generalised motions\n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Position in centimetres    \n",
    "        \n",
    "    OUTPUT:\n",
    "        g''_gp(x,v) - second partial derivative of generative process towards x\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return (32*np.exp((2*x)/5+5))/(25*(np.exp(x/5)+np.exp(5))**3)-(16*np.exp(x/5+5))/(25*(np.exp(x/5)+np.exp(5))**2)\n",
    "\n",
    "def dddg_gp(x,v):\n",
    "    \"\"\"\n",
    "    3rd partial derivative of generative process towards x, equation of sensory mapping: g'''_gp(x)  \n",
    "    Needed to calculate the sensory signal in generalised motions\n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Position in centimetres    \n",
    "        \n",
    "    OUTPUT:\n",
    "        g'''_gp(x,v) - third partial derivative of generative process towards x\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return -16*np.exp(x/5+5)*(np.exp((2*x)/5)-4*np.exp(x/5+5)+np.exp(10))/(125*(np.exp(x/5)+np.exp(5))**4)\n",
    "\n",
    "def ddddg_gp(x,v):\n",
    "    \"\"\"\n",
    "    4th partial derivative of generative process towards x, equation of sensory mapping: g''''_gp(x)  \n",
    "    Needed to calculate the sensory signal in generalised motions\n",
    "   \n",
    "    INPUTS:\n",
    "        x       - Position in centimetres    \n",
    "        \n",
    "    OUTPUT:\n",
    "        g''''_gp(x,v) - 4th partial derivative of generative process towards x\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return (16*np.exp(x/5+5)*(np.exp((3*x)/5)-11*np.exp((2*x)/5+5)+11*np.exp(x/5+10)-np.exp(15)))/(625*(np.exp(x/5)+np.exp(5))**5)\n",
    "\n",
    "# in case you wondered how to calculated all the derivatives in an easy way: https://www.derivative-calculator.net/\n",
    "\n",
    "# Show the temperature curve\n",
    "x_show = np.arange (0,50,0.01)\n",
    "y_show = g_gp(x_show,0)\n",
    "dy_show = dg_gp(x_show,0)\n",
    "plt.plot(y_show, x_show)\n",
    "#plt.plot(dy_show, x_show)\n",
    "plt.ylabel('Depth (centimeters)')\n",
    "plt.xlabel('Temperature (° C)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.vlines(17, 50, 25, colors='r', linestyles='dashed')\n",
    "plt.hlines(25, 10,17, colors='r', linestyles='dashed')\n",
    "plt.text(17.3,27,\"temparature 17° C\")\n",
    "plt.show;\n",
    "\n",
    "print('Temperature at 25 centimetres is: ', g_gp(25,0), ' degrees celsius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SIDTUDelft\\Desktop\\Thesis\\Affective-Active-Inference\\Charel_6.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SIDTUDelft/Desktop/Thesis/Affective-Active-Inference/Charel_6.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image, ImageDraw, ImageFont\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SIDTUDelft/Desktop/Thesis/Affective-Active-Inference/Charel_6.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SIDTUDelft/Desktop/Thesis/Affective-Active-Inference/Charel_6.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHydar_simulation_environment\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SIDTUDelft/Desktop/Thesis/Affective-Active-Inference/Charel_6.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, dt, t):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "\n",
    "class Hydar_simulation_environment:\n",
    "    def __init__(self, dt, t):\n",
    "        \"\"\"\n",
    "        Class that creates the simulation environment, which is the generative process in active inference terminology.\n",
    "        The simulation environment has the same structure as GYM reeinforcement Learning (RL) environment. \n",
    "        During a step the simulation environment gets the action from the agent and outputs the sensory observations as a result. \n",
    "        In contrast to RL, there is no reward given. \n",
    "        The boolean done signal is not used, the timeline (t) determines the simulation length 1..t.size\n",
    "\n",
    "        version 0.1 including the ability to generate a video\n",
    "\n",
    "        INPUTS:\n",
    "            dt      - integration time step\n",
    "            t       - timeline\n",
    "\n",
    "        Don't forget to reset the environment when starting a new simulation \n",
    "        \n",
    "        INTERNAL:\n",
    "        x[i]        - depth of Hydar at timestamp i, the hidden state \n",
    "        y[i]        - temperature of Hydar at timestamp i, the sensory state\n",
    "        u[i]        - action taken resulting in x[i], y[i] at timestamp i\n",
    "        \"\"\"\n",
    "\n",
    "        # Action and observation space\n",
    "        # self.action_space = ((-inf, inf), (-5.0, 5.0))\n",
    "        # self.action_space = float64\n",
    "        # self.observation_space = float64\n",
    "\n",
    "        self.dt = dt # integration time step\n",
    "        self.N= t.size # amount of data points\n",
    "        self.t=t # timeline\n",
    "        \n",
    "        # Images for the rendering\n",
    "        self.water_image = Image.open(\"/kaggle/input/graphics/hydar_water_background.jpg\").resize((1000, 750))  # water background 4000x3000 pixels\n",
    "        self.hydar_image_large = Image.open(\"/kaggle/input/graphics/hydar.png\") # hydar image 246*208\n",
    "        self.hydar_image = self.hydar_image_large.resize((65, 50)) \n",
    "\n",
    "\n",
    "\n",
    "    def reset(self, v, x_init, Sigma2_x, Sigma2_y, s2, noise_method, p, gen_y_method):\n",
    "        \"\"\"\n",
    "        Reset the environment to its initial state\n",
    "        To be executed before a new simulation\n",
    "        \n",
    "        INPUTS:\n",
    "        v             - Generative model causal state\n",
    "        x_init        - Hydars actual starting depth, used in generative model\n",
    "        Sigma2_x      - Variance of the hidden state mu_x\n",
    "        Sigma2_y      - Variance of the sensory observation mu_y\n",
    "        s2            - Temporal smoothness , variance of the Gaussian convolution filter to create colored noise            - \n",
    "        noise_method  - white, smooth or none\n",
    "        p             - Embedding order of generalised motions of the generative model\n",
    "        gen_y_method  - Method to generalize the sensory observations: exact, backward, extend\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = np.zeros(self.N) # Depth sequence\n",
    "        self.y = np.zeros(self.N) # Temperature sequence= Sensory signal   \n",
    "        self.u = np.zeros(self.N) # Action sequence \n",
    "        self.v = v                # generative model hidden cause\n",
    "        self.x[0] = x_init        # starting position\n",
    "        self.Sigma2_x = Sigma2_x  # Variance of the hidden state \n",
    "        self.Sigma2_y = Sigma2_y  # Variance of the sensory observation \n",
    "        self.noise_method = noise_method # noise method \n",
    "        self.s2 = s2              # Temporal smoothness, variance of the filter\n",
    "        self.p = p # Embedding order of generalised motions, only needed to generate the sensory observations in generalised motions\n",
    "        self.gen_y_method = gen_y_method # Method to generalize the sensory observations: exact, backward, extend\n",
    "        self.i = 0                # timestep-counter\n",
    "\n",
    "        \n",
    "        # Construct noise signals with temporal smoothness if required:\n",
    "        np.random.seed(42)\n",
    "        if noise_method == 'smooth' or noise_method == 'colored':\n",
    "            # And generate the smooth noise\n",
    "            self.w = self.makeNoise(self.Sigma2_x,self.s2,self.t)\n",
    "            self.z = self.makeNoise(self.Sigma2_y,self.s2,self.t)\n",
    "\n",
    "        if noise_method == 'white':\n",
    "            self.y[0]=g_gp(self.x[0],self.v) + np.random.randn(1) * np.sqrt(self.Sigma2_y)\n",
    "        elif noise_method == 'smooth' or noise_method == 'colored':\n",
    "            self.y[0]=g_gp(self.x[0],self.v)+ self.z[0,0] \n",
    "        else: #no noise\n",
    "            self.y[0]=g_gp(self.x[0],self.v)\n",
    "            \n",
    "        y_tilde=generalize_extend(self.y[0],self.p)\n",
    "        \n",
    "        # Create the initial sensory observation with the correct embedding order / method\n",
    "        if self.p==0:\n",
    "            y_tilde = self.y[0]\n",
    "        if self.gen_y_method=='exact':\n",
    "            y_tilde = sensor_generalize_exact(self.y[0],self.p,self.x[0],self.v,0)\n",
    "            #print(y_tilde)\n",
    "        elif self.gen_y_method=='backward':\n",
    "            y_tilde = sensor_generalize_backward(self.y,0,self.p)\n",
    "        elif self.gen_y_method=='extend':\n",
    "            y_tilde = generalize_extend(self.y[0],self.p)\n",
    "        else:\n",
    "            raise ValueError('Unknown method to create sensory observation in generalised coordinates of motion')\n",
    "        \n",
    "        return y_tilde \n",
    "    \n",
    "    def makeNoise(self, C, s2, t):\n",
    "        \"\"\"\n",
    "        Generate random noise series with temporal smoothness with desired covariance matrix\n",
    "        Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n",
    "\n",
    "        INPUTS:\n",
    "            C       - desired covariance matrix\n",
    "            s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n",
    "                      - s2 <= 1e-5 -> produces white noise\n",
    "            t       - timeline \n",
    "\n",
    "        OUTPUT:\n",
    "            ws       - noise sequence with temporal smoothness\n",
    "        \"\"\"\n",
    "\n",
    "        if np.size(C)== 1:\n",
    "            n = 1\n",
    "        else:\n",
    "            n = C.shape[1]  # dimension of noise\n",
    "\n",
    "        # Create the white noise with correct covariance\n",
    "        N = np.size(t)      # number of elements\n",
    "        L =cholesky(C, lower=True)  #Cholesky method\n",
    "        w = np.dot(L,np.random.randn(n,N))\n",
    "\n",
    "        if s2 <= 1e-5: # return white noise\n",
    "            return w\n",
    "        else: \n",
    "            # Create the noise with temporal smoothness\n",
    "            P = toeplitz(np.exp(-t**2/(2*s2)))\n",
    "            F = np.diag(1./np.sqrt(np.diag(np.dot(P.T,P))))\n",
    "            K = np.dot(P,F)\n",
    "            ws = np.dot(w,K)\n",
    "            return ws\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        assert isinstance(action, float), \"Action must be a float!\"\n",
    "        \n",
    "        i=self.i # to keep the code readable\n",
    "                \n",
    "        if i >= self.N-1:\n",
    "                raise ValueError('Error, simulation step > timeline') \n",
    "                   \n",
    "        # Environment's dynamics\n",
    "        if self.noise_method == 'white':\n",
    "            x_dot= f_gp(self.x[i],self.v, action) + np.random.randn(1) * np.sqrt(self.Sigma2_x)\n",
    "            self.x[i+1]= self.x[i] + self.dt*x_dot\n",
    "            self.y[i+1] = g_gp(self.x[i+1],self.v) + np.random.randn(1) * np.sqrt(self.Sigma2_y)\n",
    "        elif self.noise_method == 'smooth' or self.noise_method == 'colored':\n",
    "            x_dot= f_gp(self.x[i],self.v,action) + self.w[0,i]\n",
    "            self.x[i+1]= self.x[i] + self.dt*x_dot\n",
    "            self.y[i+1] = g_gp(self.x[i+1],self.v) + self.z[0,i]\n",
    "        else: #no noise\n",
    "            x_dot=f_gp(self.x[i],self.v,action)\n",
    "            self.x[i+1]= self.x[i] + self.dt*x_dot\n",
    "            self.y[i+1] = g_gp(self.x[i+1],self.v)\n",
    "\n",
    "        self.u[i+1]=action\n",
    "        \n",
    "         # Create the sensory observations with the requested embedding order / method\n",
    "        if self.p==0:\n",
    "            y_tilde = self.y[i+1]\n",
    "        if self.gen_y_method=='exact':\n",
    "            y_tilde = sensor_generalize_exact(self.y[i+1],self.p,self.x[i+1],self.v,action)\n",
    "            #print(y_tilde)\n",
    "        elif self.gen_y_method=='backward':\n",
    "            y_tilde = sensor_generalize_backward(self.y,i+1,self.p)\n",
    "        elif self.gen_y_method=='extend':\n",
    "            y_tilde = generalize_extend(self.y[i+1],self.p)\n",
    "        else:\n",
    "            raise ValueError('Unknown method to create sensory observation in generalised coordinates of motion')   \n",
    "        \n",
    "        \n",
    "        self.i = self.i+1\n",
    "        \n",
    "        info = \"\" # Additional information, if needed\n",
    "        \n",
    "        if self.i>= self.N-1:\n",
    "            done=True\n",
    "        else:\n",
    "            done=False\n",
    "        \n",
    "        return y_tilde, 0, done, info\n",
    "\n",
    "    \n",
    "    def render(self,i, max_depth=50, mu_x=None, mu_v=None, prior=None, actiontime=None, mode='human'):\n",
    "        \"\"\"\n",
    "        Draw a frame/image of Hydar in the water at timestep i\n",
    "        Additional data can be given as input to be displayed in image as well.\n",
    "\n",
    "        INPUTS:\n",
    "\n",
    "        i           - timestep to be shown \n",
    "        mode        - output type human (show on screen), rgb_array (frame for video)\n",
    "        prior       - optional additional time series with the prior\n",
    "        mu_x        - optional additional time series with the hidden state\n",
    "        mu_v        - optional additional time series with the causal state\n",
    "        actiontime  - optional additional timestep when action is enabled\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create a copy of the water image so as not to modify the original\n",
    "        frame = self.water_image.copy()\n",
    "        \n",
    "        # The Hydar image's alpha channel is used as the mask\n",
    "        mask = self.hydar_image.convert(\"RGBA\").split()[-1]\n",
    "        \n",
    "        # Use the max depth to scale the depth\n",
    "        scaler = (self.water_image.height - self.hydar_image.height) / max_depth\n",
    "        depth = int(self.x[i] * scaler )\n",
    "        \n",
    "        # Calculate the amount of colums/data to be shown\n",
    "        column = 2 # always shown depth and temperature\n",
    "        if mu_x!=None: column=column+1\n",
    "        if mu_v!=None: column=column+1\n",
    "        if prior!=None: column=column+1\n",
    "        colum_width_major=int(frame.width*2/10)\n",
    "        colum_width_minor=int(frame.width*1/10)\n",
    "        # the horzontal position of Hydar\n",
    "        if column==2:\n",
    "            xpos=int(frame.width*1/2)\n",
    "        else:\n",
    "            xpos=int(frame.width*1/3) \n",
    "        if actiontime==None:\n",
    "            # if no action time is given do show all actions\n",
    "            actiontime=0\n",
    "        \n",
    "        # Draw the hydar image at the specified x,y coordinate (y=depth)\n",
    "        frame.paste(self.hydar_image, (xpos, depth ), mask=mask) \n",
    "        \n",
    "        draw = ImageDraw.Draw(frame)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",30)\n",
    "        except IOError:\n",
    "            print(\"Font not found, using default font.\")\n",
    "            font = ImageFont.load_default()\n",
    "            \n",
    "        # Draw an orange horizontal line at the depth of hydra and show depth\n",
    "        draw.line((int(xpos + self.hydar_image.width), depth, int(xpos + self.hydar_image.width+colum_width_major), depth), fill=\"orange\", width=3)      \n",
    "        draw.text((int(xpos + self.hydar_image.width), depth), \"Depth: \" + \"{:.2f}\".format(self.x[i]), fill=\"white\", font=font)\n",
    "        \n",
    "        # Draw a red horizontal line at the depth of hydra and show temperature\n",
    "        draw.line((int(xpos-colum_width_major), depth, int(xpos), depth), fill=\"red\", width=3)      \n",
    "        draw.text((int(xpos-colum_width_major), depth), \"Temp: \" + \"{:.2f}\".format(self.y[i]), fill=\"white\", font=font)\n",
    "       \n",
    "        # Draw the clock bottom left\n",
    "        draw.text((int(frame.width*1/10)+10, frame.height-50), \"Time: \" + \"{:.2f}\".format(self.t[i]), fill=\"white\", font=font)\n",
    "        \n",
    "        # Draw propulsion  \n",
    "        if i>=actiontime:\n",
    "            draw.text((int(xpos + self.hydar_image.width/2+10), depth+60), \"Propulsion: \" + \"{:.2f}\".format(self.u[i]), fill=\"white\", font=font)\n",
    "            draw.line((int(xpos + self.hydar_image.width/2), depth+self.hydar_image.height+10, int(xpos + self.hydar_image.width/2), depth+self.hydar_image.height+50), fill=\"orange\", width=3)\n",
    "        else:\n",
    "            draw.text((int(xpos + self.hydar_image.width/2+10), depth+60), \"Action disabled\", fill=\"white\", font=font)\n",
    "            \n",
    "        if self.u[i]<0 and i>=actiontime:\n",
    "            # negative propulsion is moving up, Arrow up\n",
    "            arrowhead = [\n",
    "                (int(xpos + self.hydar_image.width/2), depth+self.hydar_image.height+10),  # Tip of the arrow\n",
    "                (int(xpos + self.hydar_image.width/2) - 5, depth+self.hydar_image.height+20), # Left base of the arrowhead\n",
    "                (int(xpos + self.hydar_image.width/2) + 5, depth+self.hydar_image.height+20)]  # Right base of the arrowhead\n",
    "            draw.polygon(arrowhead, fill=\"orange\")\n",
    "        elif self.u[i]>0 and i>=actiontime:\n",
    "            # positive propoulsion is moving down, arrow down\n",
    "            arrowhead = [\n",
    "                (int(xpos + self.hydar_image.width/2), depth+self.hydar_image.height+50),  \n",
    "                (int(xpos + self.hydar_image.width/2) - 5, depth+self.hydar_image.height+40),\n",
    "                (int(xpos + self.hydar_image.width/2) + 5, depth+self.hydar_image.height+40)]\n",
    "            draw.polygon(arrowhead, fill=\"orange\")\n",
    "        #else:\n",
    "          #  ; #No propulsion thus no arrow head, do nothing\n",
    "        \n",
    "        # draw additional data in the image if given\n",
    "        count=0\n",
    "        if prior!=None:\n",
    "            count=count+1\n",
    "            draw.line((int(frame.width*9/10-colum_width_minor*count), prior*scaler, int(frame.width*9/10-colum_width_minor*(count-1)), prior*scaler), fill=\"black\", width=3)      \n",
    "            draw.text((int(frame.width*9/10-colum_width_minor*count ), prior*scaler), \" \"+\"{:.2f}\".format(prior), fill=\"white\", font=font) \n",
    "            draw.text((int(frame.width*9/10-colum_width_minor*count ), prior*scaler-40), \" prior\", fill=\"white\", font=font) \n",
    "        if mu_v!=None:\n",
    "            count=count+1\n",
    "            draw.line((int(frame.width*9/10-colum_width_minor*count), mu_v*scaler, int(frame.width*9/10-colum_width_minor*(count-1)), mu_v*scaler), fill=\"purple\", width=3)      \n",
    "            draw.text((int(frame.width*9/10-colum_width_minor*count ), mu_v*scaler), \" \"+\"{:.2f}\".format(mu_v), fill=\"white\", font=font) \n",
    "            draw.text((int(frame.width*9/10-colum_width_minor*count ), mu_v*scaler-40), \" mu_v\", fill=\"white\", font=font) \n",
    "        if mu_x!=None:\n",
    "            count=count+1\n",
    "            draw.line((int(frame.width*9/10-colum_width_minor*count), mu_x*scaler, int(frame.width*9/10-colum_width_minor*(count-1)), mu_x*scaler), fill=\"green\", width=3)      \n",
    "            draw.text((int(frame.width*9/10-colum_width_minor*count ), mu_x*scaler), \" \"+\"{:.2f}\".format(mu_x), fill=\"white\", font=font) \n",
    "            draw.text((int(frame.width*9/10-colum_width_minor*count ), mu_x*scaler-40), \" mu_x\", fill=\"white\", font=font) \n",
    "\n",
    "            \n",
    "        # draw the scales\n",
    "        for divider in np.linspace(0, max_depth, 5):\n",
    "            draw.line((int(frame.width*9/10), divider * scaler , int(frame.width), divider * scaler ), fill=\"orange\", width=3)      \n",
    "            draw.text((int(frame.width*9/10), divider * scaler ), \" \" + \"{:.2f}\".format(divider), fill=\"white\", font=font)\n",
    "            draw.line((int(frame.width*1/10), divider * scaler , int(0), divider * scaler ), fill=\"red\", width=3)      \n",
    "            draw.text((int(1), divider * scaler ), \" \" + \"{:.2f}\".format(g_gp(divider,0)), fill=\"white\", font=font)\n",
    "    \n",
    "        if mode == 'rgb_array':\n",
    "            return np.array(frame)\n",
    "        \n",
    "        plt.axis('off') # to turn off axes\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        \n",
    "    def render_credits (self, credittext=None,  mode='human'):\n",
    "        \"\"\"\n",
    "        Draw a credits screen\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create a copy of the water image so as not to modify the original\n",
    "        frame = self.water_image.copy()\n",
    "        \n",
    "        # The Hydar image's alpha channel is used as the mask\n",
    "        mask = self.hydar_image_large.convert(\"RGBA\").split()[-1]\n",
    "        \n",
    "        draw = ImageDraw.Draw(frame)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",30)\n",
    "        except IOError:\n",
    "            print(\"Font not found, using default font.\")\n",
    "            font = ImageFont.load_default()\n",
    "        \n",
    "        try:\n",
    "            font_small = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",20)\n",
    "        except IOError:\n",
    "            print(\"Font not found, using default font.\")\n",
    "            font_small = ImageFont.load_default()\n",
    "        \n",
    "        if credittext!=None:\n",
    "            draw.text((int(frame.width*1.5/10), int(frame.height*1/10)), credittext, fill=\"white\", font=font)\n",
    " \n",
    "        # Draw the hydar image at the specified x,y coordinate (y=depth)\n",
    "        frame.paste(self.hydar_image_large, (int(frame.width/2-self.hydar_image_large.width/2), int(frame.height*9/10-self.hydar_image_large.height) ), mask=mask) \n",
    "       \n",
    "        # Draw the credits bottom left\n",
    "        draw.text((int(frame.width*1/100), frame.height-30), \"Water photo by Cristian Palmer on unsplash.com\", fill=\"white\", font=font_small)\n",
    "   \n",
    "\n",
    "        if mode == 'rgb_array':\n",
    "            return np.array(frame)\n",
    "        \n",
    "        plt.axis('off') # to turn off axes\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        \n",
    "    def save_data (self):\n",
    "        \"\"\"\n",
    "        This function saves results/data for reporting\n",
    "        \"\"\"\n",
    "        return self.x , self.y, self.u\n",
    "\n",
    "\n",
    "    def save_as_video(self, filename=\"hydar.avi\", mu_x=None, mu_v=None, prior=None, actiontime=None, credittext=None):\n",
    "        \"\"\"\n",
    "        This function saves the results as a video. \n",
    "        Additional data can be given as input to be displayed in the video as well.\n",
    "\n",
    "        INPUTS:\n",
    "\n",
    "        filename    - avi video filename (xxx.avi) \n",
    "        prior       - optional additional time series with the prior\n",
    "        mu_x        - optional additional time series with the hidden state\n",
    "        mu_v        - optional additional time series with the causal state\n",
    "        actiontime  - optional additional timestep when action is enabled\n",
    "        \"\"\"    \n",
    "        # Scale the max depth with the height of the video/image\n",
    "        max_depth=int(max(self.x)*1.2)\n",
    "        \n",
    "        # Create the frames of the video\n",
    "        frames = [] # list to hold the frames   \n",
    "\n",
    "        # generate tile screen of the experiment with the experiment info, can be read as still\n",
    "        for i in range (10): # first image(s) , to be read as still\n",
    "            frame = self.render_credits(mode='rgb_array', credittext=credittext)\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # generate the main video\n",
    "        for i in range(N) :\n",
    "            prior_step = prior if prior is None else prior[i]\n",
    "            mu_x_step = mu_x if mu_x is None else mu_x[i]\n",
    "            mu_v_step = mu_v if mu_v is None else mu_v[i]\n",
    "\n",
    "            frame = self.render(i, max_depth= max_depth, mu_x=mu_x_step, mu_v=mu_v_step, prior= prior_step,mode='rgb_array', actiontime=actiontime)\n",
    "            frames.append(frame)\n",
    "\n",
    "        # generate credits screen of the experiment with the experiment info, can be read as still\n",
    "        for i in range (3): # last image(s) , to be read as still\n",
    "            frame = self.render_credits(mode='rgb_array', credittext=credittext)\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Define the codec using VideoWriter_fourcc and create VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        frame_height, frame_width, _ = frames[0].shape\n",
    "        out = cv2.VideoWriter(filename, fourcc, 1/self.dt, (frame_width, frame_height))\n",
    "\n",
    "        # convert frames to BGR and save as video\n",
    "        for f in frames:\n",
    "            # Convert from RGB to BGR\n",
    "            f = cv2.cvtColor(f, cv2.COLOR_RGB2BGR)\n",
    "            #output to the video file\n",
    "            out.write(f)\n",
    "        out.release()\n",
    "\n",
    "        \n",
    "# Example usage\n",
    "env = Hydar_simulation_environment(dt,t)\n",
    "observation = env.reset(0,15,0.1,0.1,1,'no noise',1,'extend')\n",
    "env.render(0, prior=25, mu_x=15, mu_v=25, actiontime=20)\n",
    "#env.render_credits(credittext=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ai_capsule():\n",
    "    \"\"\"\n",
    "        Class that constructs a group of neurons that perform Active Inference for one hidden state, one sensory input, one causal state\n",
    "        In neurology it could e.g. represent a neuron assembly\n",
    "\n",
    "        Version 0.4 including generalised coordinates of motion, hidden state estimation, causal state estimation, action\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, dt, t, mu_x_init, mu_v_init, p, Sigma2_x, Sigma2_y, Sigma2_v, a_mu_x, a_mu_v, a_u, s2, fwd_method, actiontime):  \n",
    "        \n",
    "        \"\"\"\n",
    "                INPUTS:\n",
    "        dt               - integration time step\n",
    "        t                - timeline\n",
    "        mu_x_init        - initial hidden state estimation, in generalised coordinates of motion\n",
    "        mu_v_init        - initial hidden cause estimation, in generalised coordinates of motion\n",
    "        p                - embedding order generative model, number of derevatives in generalised coordinates of motion\n",
    "        Sigma2_x         - Estimated variance of the hidden state mu_x\n",
    "        Sigma2_y         - Estimated variance of the sensory observation mu_y\n",
    "        Sigma2_v         - Estimated variance of the prior mu_v\n",
    "        a_mu_x           - perception learning rate mu_x\n",
    "        a_mu_v           - perception learning rate mu_v\n",
    "        a_mu_a           - action learning rate\n",
    "        s2               - Temporal smoothness , variance of the Gaussian convolution filter to create colored noise\n",
    "        gen_y_method     - Method to generalize the sensory observations: exact, backward, extend\n",
    "        fwd_method       - Method for the foward model: exact, sign\n",
    "        actiontime       - timestep when action is enabled\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dt = dt # integration time step\n",
    "        self.N= t.size # amount of data points\n",
    "        self.t=t # timeline\n",
    "        self.mu_x = [np.zeros((p+1, 1)) for _ in range(N)] # hidden state estimation over time in generalised coordinates of motion\n",
    "        self.mu_v = [np.zeros((p+1, 1)) for _ in range(N)] # causal state estimation over time in generalised coordinates of motion\n",
    "        self.mu_y = np.zeros(self.N)  # sensory state estimation over time \n",
    "        self.u = np.zeros(self.N) \n",
    "        self.F= np.zeros(self.N) \n",
    "        self.mu_x[0]= mu_x_init # initializing the hidden state, in generalised coordinates of motion\n",
    "        self.mu_v[0]= mu_v_init # initializing the hidden cause, in generalised coordinates of motion\n",
    "        self.u[0] = 0      # initialize the control signal as 0, no action\n",
    "        self.mu_y[0]= self.g(self.mu_x[0][0],self.mu_v[0][0])\n",
    "        self.p = p      \n",
    "        self.Sigma2_x = Sigma2_x \n",
    "        self.Sigma2_y = Sigma2_y \n",
    "        self.Sigma2_v = Sigma2_v \n",
    "        self.s2 = s2\n",
    "        self.alpha_mu_x = a_mu_x \n",
    "        self.alpha_mu_v = a_mu_v \n",
    "        self.alpha_u = a_u  \n",
    "        self.D = self.derivativeD(self.p)\n",
    "        self.I = np.identity(self.p+1)\n",
    "        self.Iv = np.ones((p+1,1))\n",
    "        self.temporalcovariance = self.temporalC(self.p,self.s2)\n",
    "        self.Pi_x = inv(np.kron(self.temporalcovariance,self.Sigma2_x)) # precision matrix of smoothened noise w\n",
    "        self.Pi_y = inv(np.kron(self.temporalcovariance,self.Sigma2_y)) # precision matrix of smoothened noise z\n",
    "        self.Pi_v = inv(np.kron(self.temporalcovariance,self.Sigma2_v)) # precision matrix of smoothened noise z\n",
    "        self.std_vec_inv=self.standard_vec_inv(p)\n",
    "        self.std_vec=self.standard_vec(p)\n",
    "        self.fwd_method = fwd_method\n",
    "        self.actiontime = actiontime\n",
    "        self.i = 0 # timestep-counter\n",
    "               \n",
    "        # Generative model parameters\n",
    "        self.a=-1 # generative model function of motion is -mu_x + mu_v, hence a = -1\n",
    "        self.b=1 # generative model function of motion is -mu_x + mu_v, hence b = 1\n",
    "        self.Atilde=self.a * self.I\n",
    "        self.Btilde=self.b * self.I\n",
    "        #self.c=1 # uncomment in case you want to test a linear model for sensory observations\n",
    "        #self.Ctilde= self.c * self.I # uncomment in case you want to tst a linear model for sensory observations\n",
    " \n",
    "        if self.p<0:\n",
    "            # unknown embedding order, error\n",
    "            raise ValueError('Embedding order forward model < 0')    \n",
    "        if self.p==0:\n",
    "            # unknown embedding order, error\n",
    "            raise ValueError('This active inference neuron class is not designed for p=0, p should be at least 1')    \n",
    "\n",
    "    def g(self,x,v):\n",
    "        \"\"\"\n",
    "            equation of sensory mapping of the generative model: g(x,v)  \n",
    "            Given as input for this example equal to the true generative process g_gp(x,v)\n",
    "        \"\"\"\n",
    "        return g_gp(x,v)\n",
    "    \n",
    "    def dx_dg(self, x,v):\n",
    "        \"\"\"\n",
    "            Partial derivative of the equation of sensory mapping of the generative model towards x: g'(x,v) towards x \n",
    "            Given as input for this example equal to the true derivative of generative process dg_gp(x,v) towards x\n",
    "        \"\"\"\n",
    "        return dg_gp(x,v)\n",
    "    \n",
    "    def dv_dg(self, x,v):\n",
    "        \"\"\"\n",
    "            Partial derivative of the equation of sensory mapping of the generative model towards x: g'(x,v) towards v \n",
    "            Given as input for this example equals to 0 (not dependend on v)\n",
    "        \"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def f(self,x,v):\n",
    "        \"\"\"\n",
    "            equation of motion of the generative model: f(x,v) \n",
    "            f(x,v) = a* mu_x + b* mu_v, where a = -1, b=1\n",
    "        \"\"\"\n",
    "        return self.a*x + self.b*v\n",
    "    \n",
    "    def dx_df(self,x,v):\n",
    "        \"\"\"\n",
    "            Partial derivative of equation of motion of the generative model: f'(x,v) towards x \n",
    "        \"\"\"\n",
    "        return self.a\n",
    "    \n",
    "    def dv_df(self, x, v):\n",
    "        \"\"\"\n",
    "            Partial derivative of equation of motion of the generative model: f'(x,v) towards v \n",
    "        \"\"\"\n",
    "        return self.b\n",
    "    \n",
    "    def fwd_model(self, x, v, u, fwd_method):\n",
    "        \"\"\"\n",
    "        Construct the forward model embedding order p \n",
    "        see: https://www.kaggle.com/code/charel/learn-by-example-active-inference-in-the-brain-5\n",
    "        \n",
    "        For this example the exact method has been calculated upto 3 derivatives\n",
    "\n",
    "        INPUTS:\n",
    "            x          - Hidden state\n",
    "            v          - Hidden cause\n",
    "            u          - Control signal\n",
    "            fwd_method - Method\n",
    "\n",
    "        OUTPUT:\n",
    "            fwd        - Forward model\n",
    "        \"\"\" \n",
    "   \n",
    "        if fwd_method == 'sign':\n",
    "            fwd = np.sign(dg_gp(x,v)) * np.ones((self.p+1,1))\n",
    "        elif fwd_method == 'exact':        \n",
    "            fwd = np.zeros((self.p+1,1))\n",
    "            if self.p>=1:\n",
    "                fwd[1] = b_gp*dg_gp(x,v)\n",
    "            if self.p>=2:\n",
    "                fwd[2] = 2*b_gp*f_gp(x,v,u)*ddg_gp(x,v) +b_gp*df_gp(x,v,u)*dg_gp(x,v)\n",
    "            if self.p>=3:\n",
    "                fwd[3] = 3*b_gp*f_gp(x,v,u)**2*dddg_gp(x,v)+4*df_gp(x,v,u)*b_gp*f_gp(x,v,u)*dg_gp(x,v)+2*df_gp(x,v,u)*b_gp*f_gp(x,v,u)*ddg_gp(x,v)+df_gp(x,v,u)**2*b_gp*dg_gp(x,v)\n",
    "        elif fwd_method == 'sign+':        \n",
    "            fwd = np.zeros((self.p+1,1))\n",
    "            if self.p>=1:\n",
    "                fwd[1] = np.sign(dg_gp(x,v))\n",
    "            if self.p>=2:\n",
    "                fwd[2] = np.sign(ddg_gp(x,v))\n",
    "            if self.p>=3:\n",
    "                fwd[3] = np.sign(dddg_gp(x,v))\n",
    "        else:\n",
    "            raise ValueError('Unknown method to create forward model')     \n",
    "\n",
    "        return fwd\n",
    "    \n",
    "    def standard_vec(self, p):\n",
    "        \"\"\"\n",
    "        Vector [1,0,0,0,0, etc] with embedding order p\n",
    "        \"\"\"\n",
    "        x = np.zeros((p+1,1))\n",
    "        x[0] = 1\n",
    "        return x\n",
    "\n",
    "    def standard_vec_inv(self, p):\n",
    "        \"\"\"\n",
    "        Vector [0,1,1,1,1,1, etc] with embedding order p\n",
    "        \"\"\"\n",
    "        x = np.ones((p+1,1))\n",
    "        x[0] = 0\n",
    "        return x\n",
    "    \n",
    "    def derivativeD(self, p):\n",
    "        \"\"\"\n",
    "        Construct derivative operator with embedding order p \n",
    "        Shifts all variables of a vector up by one and adds a zero at the bottom \n",
    "\n",
    "        Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n",
    "\n",
    "        INPUTS:\n",
    "            p       - embedding order (>0)\n",
    "\n",
    "        OUTPUT:\n",
    "            D       - derivative matrix ((p+1) x (p+1))\n",
    "        \"\"\" \n",
    "        D = toeplitz(np.zeros([1,p+1]),np.append(np.array([0,1]),np.zeros([1,p-1])))\n",
    "\n",
    "        return D\n",
    "    \n",
    "    def temporalC(self, p, s2):\n",
    "        \"\"\"\n",
    "        Construct the temporal covariance matrix S for noise with embedding order p and smoothness parameter s2\n",
    "\n",
    "        See: https://www.kaggle.com/code/charel/learn-by-example-active-inference-in-the-brain-2\n",
    "        \n",
    "        Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n",
    "\n",
    "        INPUTS:\n",
    "            p       - embedding order (>0)\n",
    "            s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n",
    "\n",
    "        OUTPUT:\n",
    "            S       - temporal covariance matrix ((p+1) x (p+1))\n",
    "        \"\"\" \n",
    "\n",
    "        q = np.arange(p+1)\n",
    "\n",
    "        r = np.zeros(1+2*(p))\n",
    "        r[2*q] = np.cumprod(1-2*q)/(2*s2)**(q)    \n",
    "\n",
    "        S = np.empty([0,p+1])\n",
    "\n",
    "        for i in range(p+1):\n",
    "            S = np.vstack([S,r[q+i]])\n",
    "            r = -r\n",
    "\n",
    "        return S \n",
    "    \n",
    "    def ai_step (self, prior, y):\n",
    "        \"\"\"\n",
    "        Perform active inference step   \n",
    "\n",
    "        INPUTS:\n",
    "            prior   - target location of the hidden causes\n",
    "            y       - sensory input signal at timestamp, in generalized coordinates of motion\n",
    "\n",
    "        INTERNAL:\n",
    "            i         - tic, timestamp\n",
    "            mu_x      - Belief or hidden state estimation, in generalized coordinates of motion\n",
    "            mu_y      - Belief or sensory signal estimation/prediction, in generalized coordinates of motion\n",
    "            mu_v      - Belief or causal state estimation, in generalized coordinates of motion\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        i=self.i # to keep the code readable\n",
    "                \n",
    "        if i >= self.N-1:\n",
    "                raise ValueError('Error, simulation step > timeline') \n",
    "        \n",
    "        #-------------------------------#\n",
    "        #                               #\n",
    "        #           Prediction          #\n",
    "        #                               #\n",
    "        #-------------------------------#\n",
    "        \n",
    "        # Note that the predictions are in generalized coordinates of motion  \n",
    "        mu_x_hat = self.std_vec*self.f(self.mu_x[i][0],self.mu_v[i][0]) + self.std_vec_inv * self.dx_df(self.mu_x[i][0],self.mu_v[i][0]) * self.mu_x[i] + self.std_vec_inv * self.dv_df(self.mu_x[i][0],self.mu_v[i][0]) * self.mu_v[i]\n",
    "        mu_y_hat = self.std_vec*self.g(self.mu_x[i][0],self.mu_v[i][0]) + self.std_vec_inv * self.dx_dg(self.mu_x[i][0],self.mu_v[i][0]) * self.mu_x[i] + self.std_vec_inv * self.dv_dg(self.mu_x[i][0],self.mu_v[i][0]) * self.mu_v[i]\n",
    "        \n",
    "        #-------------------------------#\n",
    "        #                               #\n",
    "        #        Prediction Error       #\n",
    "        #                               #\n",
    "        #-------------------------------#\n",
    "\n",
    "        # Note that the predictions erros are in generalized coordinates of motion \n",
    "        \n",
    "        eps_x = self.D.dot(self.mu_x[i]) - mu_x_hat  # prediction error hidden state\n",
    "        eps_y = y - mu_y_hat #prediction error sensory observation  \n",
    "        \n",
    "        # In case a linear state space model the prediction error can be written as (below calculation is equivalent):\n",
    "        #eps_x = (self.D-self.Atilde).dot(self.mu_x) - self.Btilde.dot(self.mu_v)  # prediction error hidden state\n",
    "        #eps_y = y - self.Ctilde.dot(self.mu_x) #prediction error sensory observation\n",
    "\n",
    "        #-------------------------------#\n",
    "        #                               #\n",
    "        # Prediction Error minimization #\n",
    "        #                               #\n",
    "        #-------------------------------#            \n",
    "     \n",
    "        #-------------------------------------#\n",
    "        # Calculate Free Energy to report out #\n",
    "        #-------------------------------------#\n",
    "        \n",
    "        self.F[i+1]= 0.5*( eps_x.T.dot(self.Pi_x).dot(eps_x) + eps_y.T.dot(self.Pi_y).dot(eps_y)).item(0) \n",
    "        # Note, the item(0) is needed to translate the python matrix result to a scaler, e.g. [[1]] to 1\n",
    "        \n",
    "        #-------------------------------#\n",
    "        # Gradient descent hidden state #\n",
    "        #-------------------------------#\n",
    "        \n",
    "        dFdmu_x = (self.D-self.dx_df(self.mu_x[i][0],self.mu_v[i][0]) * self.I).T.dot(self.Pi_x).dot(eps_x) - (self.dx_dg(self.mu_x[i][0],self.mu_v[i][0]) * self.I ).T.dot(self.Pi_y).dot(eps_y)                       \n",
    "        # In case a linear state space model is used the below calculation is equivalent\n",
    "        #dFdmu_x = (self.D-Atilde).T.dot(self.Pi_x).dot(self.eps_x) - Ctilde.T.dot(self.Pi_y).dot(self.eps_y)\n",
    "        \n",
    "        dmu_x = np.dot(self.D,self.mu_x[i]) - self.alpha_mu_x * dFdmu_x  \n",
    "        self.mu_x[i+1] = self.mu_x[i] + self.dt * dmu_x\n",
    "\n",
    "        #-------------------------------#\n",
    "        # Gradient descent causal state #\n",
    "        #-------------------------------#\n",
    "        \n",
    "        eps_v = self.mu_v[i] - prior\n",
    "        \n",
    "        dFdmu_v = (-self.dv_df(self.mu_x[i][0],self.mu_v[i][0]) * self.I).T.dot(self.Pi_x).dot(eps_x) + (-self.dv_dg(self.mu_x[i][0],self.mu_v[i][0]) * self.I ).T.dot(self.Pi_y).dot(eps_y) + self.Pi_v.dot(eps_v)\n",
    "        \n",
    "        # In case a linear state space model is used the below calculation is equivalent\n",
    "        #dFdmu_x = (-Ctilde).T.dot(self.Pi_x).dot(self.eps_x) + (self.Pi_v).dot(self.eps_p)\n",
    "        \n",
    "        dmu_v = np.dot(self.D,self.mu_v[i]) - self.alpha_mu_v * dFdmu_v  \n",
    "        self.mu_v[i+1] = self.mu_v[i] + self.dt * dmu_v\n",
    "\n",
    "        #-------------------------#\n",
    "        # Gradient descent action #\n",
    "        #-------------------------#\n",
    "        \n",
    "        if i>=self.actiontime:\n",
    "            fwd=self.fwd_model(self.mu_x[i][0], self.mu_v[i][0], self.u[i], self.fwd_method)          \n",
    "            dFdu = fwd.T.dot(self.Pi_y).dot(eps_y).item(0)\n",
    "            du = -self.alpha_u * dFdu  \n",
    "            self.u[i+1] = self.u[i] + self.dt * du\n",
    "        else:\n",
    "            self.u[i+1]=0.0\n",
    "        \n",
    "        self.mu_y[i+1]= self.g(self.mu_x[i][0],self.mu_v[i][0]) # todo, in generalised coordinates?\n",
    "        self.i = self.i+1\n",
    "        \n",
    "        return self.u[i+1]\n",
    "    \n",
    "    def save_data (self):\n",
    "        \"\"\"\n",
    "        This function saves results/data for reporting\n",
    "        \"\"\"\n",
    "        return  self.F, self.mu_v, self.mu_x, self.mu_y, self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation (name,dt,t, v, prior, x_init, Sigma2_x, Sigma2_y, Sigma2_v, noise_method, a_mu_x,a_mu_v, a_u, p, gen_y_method, fwd_method, actiontime, video=False):\n",
    "    \"\"\"\n",
    "    Simulation for perceptual inference in a dynamic environment with generalised coordinates     \n",
    "   \n",
    "    INPUTS:\n",
    "        Name          - Name of the experiment\n",
    "        v             - Generative model causal state\n",
    "        prior         - Hydars top-down prior belief/hypotheses of the desired depth (time series)\n",
    "        x_init        - Hydars actual starting depth, used in generative model\n",
    "        Sigma2_x      - Variance of the hidden state mu_x\n",
    "        Sigma2_y      - Variance of the sensory observation mu_y\n",
    "        Sigma2_v      - Variance of the sensory observation mu_z\n",
    "        noise_method  - white, smooth or none\n",
    "        a_mu_x        - Learning rate for mu_x\n",
    "        a_mu_v        - Learning rate for mu_v\n",
    "        a_u           - Learning rate for u\n",
    "        p             - Embedding order of generalised motions of the generative model\n",
    "        gen_y_method  - Method to generalize the sensory observations: exact, backward, extend\n",
    "        fwd_method    - Method for the foward model: exact, sign\n",
    "        actiontime    - Timestep when action is enabled\n",
    "    VARIABLES:\n",
    "        s2            - The variance of the Gaussian filter used to create the smoothened noise\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # this simulation code is for simulation with generalised coordinates of motion\n",
    "    if p<=0:\n",
    "        # Not generalised\n",
    "        raise ValueError('Select embedding order p > 0') \n",
    "        \n",
    "    \n",
    "    # Initialize the variance of the gausian filter (e.g. to estimate/construct colored noise):\n",
    "    np.random.seed(42)\n",
    "    if noise_method == 'white':\n",
    "        s2 = 1e-5\n",
    "    elif noise_method == 'smooth' or noise_method == 'colored' :\n",
    "        s2 = 1/2000\n",
    "    else: #no noise\n",
    "        s2 = 1/64   \n",
    "\n",
    "    # Create the simulation environment\n",
    "    env = Hydar_simulation_environment(dt,t)\n",
    "    y=env.reset(v, x_init, Sigma2_x, Sigma2_y, s2, noise_method, p, gen_y_method)\n",
    "    \n",
    "    # make prior in generalised coordinates of motion\n",
    "    prior_tilde = [generalize_extend(item, p) for item in prior] \n",
    "    \n",
    "    # Create active inference neuron\n",
    "    capsule = ai_capsule(dt, t, prior_tilde[0], prior_tilde[0], p, Sigma2_x, Sigma2_y, Sigma2_v, a_mu_x, a_mu_v, a_u, s2, fwd_method, actiontime) \n",
    "\n",
    "    # Run the simulation\n",
    "    ssim = time.time() # start sim\n",
    "\n",
    "    for i in np.arange(1,N):\n",
    "        # Calculate action using active inference step using sensory observation       \n",
    "        u = capsule.ai_step(prior_tilde[i],y)\n",
    "        # Execute action in simulation environment step with resulting sensory observation (y)\n",
    "        y, reward, done, info = env.step(u)\n",
    "    tsim = time.time() - ssim\n",
    "    #print('Simulation time: ' + \"%.2f\" % tsim + ' sec' )   \n",
    "    \n",
    "    # Get the data for reporting\n",
    "    x, y, u = env.save_data()\n",
    "    F, mu_v_new, mu_x_new, mu_y, same_u = capsule.save_data()\n",
    "\n",
    "    # Use only the first entry of the generalised coordinates for reporting purposes  \n",
    "    mu_x_0 = np.array([mu_x_e[0][0] for mu_x_e in mu_x_new])\n",
    "    mu_v_0 = np.array([mu_v_e[0][0] for mu_v_e in mu_v_new])\n",
    "    \n",
    "    MSE=sum((mu_y-y)**2) # Mean Squared Error resulting sensory observation\n",
    "    EFE=sum(F) # sum of the free energy over all timesteps can be regarded as the Expected Free Energy (of the future) at the start of the sequence\n",
    "    \n",
    "    if video==True:\n",
    "        credittext = \"Name: \"+ name+\"\\n\"\n",
    "        credittext = credittext + \"Sigma2_x= {:.2f},  Sigma2_y= {:.2f},  Sigma2_v= {:.2f} \\n \".format(Sigma2_x,Sigma2_y,Sigma2_v)\n",
    "        credittext = credittext + \"LR mu_x= {:.2f}, LR u= {:.2f}, LR mu_v= {:.2f} \\n \".format(a_mu_x,a_u,a_mu_v)\n",
    "        credittext = credittext + \"init x= {:.2f}, prior= {:.2f} \\n \".format(x_init,prior[0])\n",
    "        credittext = credittext + \"init mu_x= {:.2f}, init u= 0, init mu_v= {:.2f} \\n \".format(prior[0],prior[0])\n",
    "        credittext = credittext + \"Embedding order= \"+str(p)+\", Noise method= \"+noise_method + \"\\n\"\n",
    "        credittext = credittext + \"Gen y method= \"+gen_y_method+\", Fwd method= \"+fwd_method + \"\\n\"\n",
    "        video=env.save_as_video('hydar_'+name+'.avi', prior=prior,mu_x=mu_x_0, mu_v=mu_v_0, actiontime=actiontime, credittext=credittext )\n",
    "    \n",
    "   \n",
    "    return F, mu_v_0, mu_x_0, mu_y, x, y, u, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph (experimentname, text1, F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1):\n",
    "    '''\n",
    "    Plot results of a single experiment\n",
    "    '''\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, sharex='col');\n",
    "    fig.suptitle(experimentname+\" \"+text1);\n",
    "    plt.annotate(\"MSE \"+text1+\": \"+\"{:.0f}\".format(MSE1), (1.05,0), (0, 20), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "    axes[0].plot(t[1:],mu_x1[1:],label='belief $\\mu_x$ '+text1);\n",
    "    axes[0].plot(t[1:],x1[1:],label='Generative process '+text1);\n",
    "    axes[0].plot(t[1:],mu_v1[1:],label='causal belief $\\mu_v$ '+text1)\n",
    "    axes[0].plot(t[1:],prior[1:],label='Prior belief', color='black')\n",
    "    axes[0].set_ylabel('Depth');\n",
    "    axes[0].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[0].ticklabel_format(useOffset=False)\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].grid(1);\n",
    "    \n",
    "    axes[1].plot(t[1:],mu_y1[1:],label='belief $\\mu_x$  '+text1);\n",
    "    axes[1].plot(t[1:],y1[1:],label='Generative process '+text1);\n",
    "    axes[1].plot(t[1:],g_gp(mu_v1[1:],0),label='causal belief $\\mu_v$ '+text1)\n",
    "    axes[1].plot(t[1:],g_gp(prior[1:],0),label='Prior belief', color='black')\n",
    "    axes[1].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[1].set_ylabel('Temp');\n",
    "    axes[1].ticklabel_format(useOffset=False)\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[1].grid(1);\n",
    "\n",
    "    axes[2].plot(t[1:],u1[1:],label='Control signal '+text1);\n",
    "    axes[2].set_ylabel('Control');\n",
    "    axes[2].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[2].ticklabel_format(useOffset=False)\n",
    "    axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[2].grid(1);\n",
    "\n",
    "    axes[3].plot(t[1:],F1[1:],label='Free Energy '+text1);\n",
    "    axes[3].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[3].set_xlabel('time [s]');\n",
    "    axes[3].set_ylabel('FE');\n",
    "    axes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[3].grid(1);   \n",
    "    \n",
    "def plot_graph_compare (experimentname, text1, F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1, text2, F2, mu_v2, mu_x2, mu_y2, x2, y2, u2, MSE2):\n",
    "    '''\n",
    "    Plot results comparing 2 experiments\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(4, 1, sharex='col');\n",
    "    fig.suptitle(experimentname+\" \"+text1+\" vs \"+text2);\n",
    "    plt.annotate(\"MSE \"+text1+\": \"+\"{:.0f}\".format(MSE1), (1.05,0), (0, 5), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "    plt.annotate(\"MSE \"+text2+\": \"+\"{:.0f}\".format(MSE2), (1.05,0), (0, -5), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "    axes[0].plot(t[1:],mu_x1[1:],label='belief $\\mu_x$ '+text1);\n",
    "    axes[0].plot(t[1:],x1[1:],label='Generative process '+text1);\n",
    "    axes[0].plot(t[1:],mu_v1[1:],label='causal belief $\\mu_v$ '+text1)\n",
    "    axes[0].plot(t[1:],mu_x2[1:],label='belief $\\mu_x$ '+text2);\n",
    "    axes[0].plot(t[1:],x2[1:],label='Generative process '+text2);\n",
    "    axes[0].plot(t[1:],mu_v2[1:],label='causal belief $\\mu_v$ '+text2)\n",
    "    axes[0].plot(t[1:],prior[1:],label='Prior belief', color='black')\n",
    "    axes[0].set_ylabel('Depth');\n",
    "    axes[0].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[0].ticklabel_format(useOffset=False)\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].grid(1);\n",
    "    axes[1].plot(t[1:],mu_y1[1:],label='belief $\\mu_x$  '+text1);\n",
    "    axes[1].plot(t[1:],y1[1:],label='Generative process '+text1);\n",
    "    axes[1].plot(t[1:],g_gp(mu_v1[1:],0),label='causal belief $\\mu_v$ '+text1)\n",
    "    axes[1].plot(t[1:],mu_y2[1:],label='belief $\\mu_x$  '+text1);\n",
    "    axes[1].plot(t[1:],y2[1:],label='Generative process '+text1);\n",
    "    axes[1].plot(t[1:],g_gp(mu_v2[1:],0),label='causal belief $\\mu_v$ '+text1)\n",
    "    axes[1].plot(t[1:],g_gp(prior[1:],0),label='Prior belief', color='black')\n",
    "    axes[1].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[1].set_ylabel('Temp');\n",
    "    axes[1].ticklabel_format(useOffset=False)\n",
    "    #axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[1].grid(1);\n",
    "\n",
    "    axes[2].plot(t[1:],u1[1:],label='Control signal '+text1);\n",
    "    axes[2].plot(t[1:],u2[1:],label='Control signal '+text2);\n",
    "    axes[2].set_ylabel('Control');\n",
    "    axes[2].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[2].ticklabel_format(useOffset=False)\n",
    "    axes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[2].grid(1);\n",
    "\n",
    "    axes[3].plot(t[1:],F1[1:],label='Free Energy '+text1);\n",
    "    axes[3].plot(t[1:],F2[1:],label='Free Energy '+text2);\n",
    "    axes[3].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[3].set_xlabel('time [s]');\n",
    "    axes[3].set_ylabel('FE');\n",
    "    axes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[3].grid(1);\n",
    "    \n",
    "def plot_graph_small (experimentname, text1, F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1):\n",
    "    '''\n",
    "    Plot results of a single experiment compressed\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2, 1, sharex='col', figsize=(7,3));\n",
    "    fig.suptitle(experimentname+\" \"+text1);\n",
    "    plt.annotate(\"MSE \"+text1+\": \"+\"{:.0f}\".format(MSE1), (1.05,0), (0, 20), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "    axes[0].plot(t[1:],mu_x1[1:],label='belief $\\mu_x$ '+text1);\n",
    "    axes[0].plot(t[1:],x1[1:],label='Generative process '+text1);\n",
    "    axes[0].plot(t[1:],mu_v1[1:],label='causal belief $\\mu_v$ '+text1)\n",
    "    axes[0].plot(t[1:],prior[1:],label='Prior belief', color='black')\n",
    "    axes[0].set_ylabel('Depth');\n",
    "    axes[0].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[0].ticklabel_format(useOffset=False)\n",
    "    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[0].grid(1);\n",
    "    \n",
    "\n",
    "    axes[1].plot(t[1:],u1[1:],label='Control signal '+text1);\n",
    "    axes[1].set_ylabel('Control');\n",
    "    axes[1].axvline(x=actiontime*T, color='r', linestyle='--')\n",
    "    axes[1].ticklabel_format(useOffset=False)\n",
    "    axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    axes[1].grid(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = 30.0 # generative process initial depth Hydar\n",
    "v = 0 # generative process causal depth but in this example v is not used\n",
    "prior = np.ones(N) * 25.0 # Hydars top-down prior belief of the (target) depth\n",
    "\n",
    "actiontime=0.20\n",
    "experimentname='experiment 601'\n",
    "# simulation parameters                               (experimentname,dt,t,v,prior,x_init,S2_x,S2_y,S2_v,noise,a_x,a_v,a_u,p, y_method, fwd_method,actiontime,yes/no video):\n",
    "F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1 = simulation(experimentname,dt,t,v,prior,x_init,0.1,0.1,0.1,'no noise',1,1,  50,1,'exact', 'exact',actiontime*N,video=False) # \n",
    "\n",
    "# plot results\n",
    "plot_graph(experimentname,\"\",F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = 30.0 # generative process initial depth Hydar\n",
    "v = 0 # generative process causal depth but in this example v is not used\n",
    "prior = np.ones(N) * 25.0 # Hydars top-down prior belief of the (target) depth\n",
    "\n",
    "actiontime=0.20\n",
    "experimentname='Experiment 6.06 colored noise'\n",
    "# simulation parameters                               (experimentname,dt,t,v,prior,x_init,S2_x,S2_y,S2_v,noise,a_x,a_v,a_u,p, y_method, fwd_method,actiontime,yes/no video):\n",
    "F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1 = simulation(experimentname,dt,t,v,prior,x_init,5,0.1,0.1,'smooth',8,3,150,2,'exact', 'exact',actiontime*N,video=False) # \n",
    "F2, mu_v2, mu_x2, mu_y2, x2, y2, u2, MSE2 = simulation(experimentname,dt,t,v,prior,x_init,0.1,0.1,0.1,'smooth',8,3,150,2,'exact', 'exact',actiontime*N,video=False) # \n",
    "\n",
    "\n",
    "# plot results\n",
    "plot_graph(experimentname,\"high variance hidden state\",F1, mu_v1, mu_x1, mu_y1, x1, y1, u1, MSE1 )\n",
    "plot_graph(experimentname,\"low variance hidden state\",F2, mu_v2, mu_x2, mu_y2, x2, y2, u2, MSE2 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Affective-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
